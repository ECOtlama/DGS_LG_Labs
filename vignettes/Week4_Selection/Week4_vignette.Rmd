---
title: "Week 4: Selection"
author: 
- "Andrew Eckert (worked example)"
- "Helene Wagner (vignette)"
date: "`r Sys.Date()`"
show_toc: true
output:
  knitr:::html_vignette:
    toc: yes
    fig_width: 4 
    fig_height: 3.5
vignette: >
  %\VignetteIndexEntry{Week 4: Selection}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## 1. Overview of Worked Example

### a) Goals 

**Justification**:Natural selection acts on phenotypic variation that is genetically determined. As such, it can be difficult to get a complete picture about adaptation from scanning genomes using molecular markers. The reason is that genetic outliers, even if true positives, have little to no information present about what phenotype they affect and how this phenotype results in fitness differences. Moreover, it is debatable to scan genomes for the presence of outliers if you have yet to demonstrate that the populations being sampled are locally adapted.

**Learning Objectives**:This lab was constructed to give you experience in working with basic quantitative and population genetic analyses useful to testing hypotheses about local adaptation. Phenotypic measurement is undergoing a revolution, so that familiarity with basic methods in quantitative genetics will serve you well in the future. By the end of the laboratory, you should be able to do the following:

- Construct, fit, and assess linear mixed models (LMMs) to estimate genetic values for a phenotypic trait measured for families existing in a common garden.
- Use LMMs to estimate heritability of a trait, its differentiation among populations, and its correlation with environment.

In addition, this week's bonus material shows how to: 

- Test whether or not phenotypic trait differentiation is statistically different than genetic differentiation at random molecular markers.
- Perform and assess output from basic association analyses linking genetic variation with environmental variation. We will return to the topic of outlier locus detection and gene-environment associations later in the course (Week 11).

### b) Data set 

The data with which you are working come from a study of western white pine (Pinus monticola Dougl. ex D. Don) sampled around the Lake Tahoe Basin of California and Nevada. These data consist of 157 trees sampled from 10 populations (n = 9 to 22 trees/population). Within each population, trees were sampled within three plots. For each plot, GPS coordinates were collected (i.e. each plot in each population has its own GPS coordinates) and used to generate a set of 7 environmental variables. From these trees, needle tissue was collected from which total DNA was extracted and genotyped for 164 single nucleotide polymorphisms (SNPs). Seeds were also collected and planted in a common garden. The seedlings (n = 5 to 35/tree) were measured for several phenotypic traits. The phenotypic trait we will be working with today is known as the carbon isotope ratio ($δ^{13}C$). It is the ratio of two isotopes of carbon ($^{13}C$ and $^{12}C$) relative to an experimental control, and it is strongly correlated with intrinsic water-use efficiency in plants. Plants need water to live, so it is not a stretch of the imagination to believe that this phenotypic trait has a link with plant fitness.

We will thus have three types of data:

- **WWP_SNP_genotypes.txt**: SNP genotypes for all trees sampled in the field.
- **WWP_environmental_data.txt**:Environmental data collected from each plot within each population.
- **WWP_phenotype_data.txt**: Phenotypic measurements for 5 seedlings per tree made in a common garden.

### c) Required R libraries

All required packages should have been installed already when you installed 'LandGenCourse'.

```{r message=FALSE, warning=TRUE}

#devtools::install_github("krlmlr/here")
require(here)
require(LandGenCourse)
require(lme4)
require(car)
#require(EcoGenetics)
require(tibble)

source(paste0(here(),"/data/supplemental_R_functions.R"))

if(!dir.exists(paste0(here(),"/data"))) dir.create(paste0(here(),"/data"))
```

## 2. Estimate genetic values for an observed phenotypic trait

**Motivation**: A lot of genetics can be carried out without use of any molecular markers. Practitioners of empirical population genetics forget this quite often. A common garden allows us to create a standardized environment in which we minimize the influence of environment on the expression of a particular phenotypic trait. Since we know, after over a century of showing it to be true, that phenotypic variation results from genetic variation, environmental variation, and the interaction of genetic and environmental variation, then if we standardize the environment, phenotypic variation we see in the common garden is due to genetic variation (or if multiple gardens are used, genetics and the interaction of genetics and the environment).

**Goals & Background**: The goal for this part of the laboratory is to construct, fit, and assess LMMs for $δ^{13}C$. We will be using the data in the file named "WWP_phenotypic_data.txt". These data are organized in a tab-delimited text file with seedlings grouped by maternal tree (i.e. its mother tree), plot, and population. Also included is an experimental treatment known as “block”. In a common garden, seedlings from the same maternal tree are randomized among blocks to avoid the influence of micro-environmental variation on expression of phenotypic traits.

### a) Import phenytypic data 

```{r}
phen <- read.delim(paste0(here(),"/data/WWP_phenotype_data.txt"), sep = "\t", header = T)
as.tibble(phen)
```

### b) Fit linear models to phenotypic trait data

Now,we are ready to fit a series of linear models. We will fit three models in total for this laboratory: 
- **mod1**: a fixed effect model with only an intercept, 
- **mod2**:a LMM with an intercept (fixed) and a random effect due to family, and 
- **mod3**:a LMM with an intercept, a random effect due to family nested within population, and a random effect of population. We will thus be ignoring the plot identifiers. All models will also have a fixed effect of block.

```{r}
mod1<-lm(phen$d13c~1+phen$block)
mod2<-lmer(d13c~1+(1|family)+block,data = phen, REML = F)
mod3 <- lmer(d13c ~ 1 + (1|population/family) + block, data = phen, REML = F)
```

We are now ready to explore each of these models and to look at which model best fits our data. First, you can use the Anova() function in the car library to test the statistical significance of the fixed terms in each mod. This function let's us control the type of sums of squares (SS) being used, here type III sums of squares (see your stats book).

Note that for modelsl fitted with 'lmer' (models 2 & 3) and with 'REML = F', we need to use a chi-squared test. An alternative would be to specifiy 'REML = T'. However, further down we will need the likelihood (calculated with 'REML = F') to look at model performance (as opposed to the approximate REML value generated with 'REML = T').


```{r}
Anova(mod1, type="III", test.statistic = "F")
Anova(mod2, type="III", test.statistic = "Chisq")
Anova(mod3, type="III", test.statistic = "Chisq")
```
Compare the output. What do you conclude about the effect of block in each of the models? Remember this is an experimental treatment, so your conclusion directly addresses whether micro-environmental variation exists in your common garden.

### c) Compare model fit

Now, let’s explore which model best fits our data. To do this we will use the Akaike Information Criterion (AIC). This statistic is like a penalized likelihood score, where the penalty increases as the number of parameters in a model increases. When using AIC, the model with the lowest score is the preferred model. To get AIC values for each model, do something like the following using the AIC() function.

```{r}
aic_vals <- c(AIC(mod1), AIC(mod2), AIC(mod3))
names(aic_vals) <- c("mod1","mod2","mod3")
aic_vals
```

We can express the relative support of each model using Akaike weights. These can be thought of as the conditional probabilities of each model. To do this, we will need to write a few lines of R commands. Luckily for you, I have provided a function named aic_weights that will calculate these for you. This function is located in the "supplemental_R_functions.R" file. Use source("supplemental_R_functions.R") to get these into R.

```{r}
aic_out <- aic_weights(aic_vals)
aic_out
```

Inspect the values in aic_out. They add to one and can be thought of as conditional probabilities of each model, with the conditioning being on only these three models being examined. Which model has the highest probability? How much larger is it than the other probabilities? What does this tell you about your optimal model?

### d) Calculate genetic values for maternal trees

Now that we have the best model, let’s use it to calculate the genetic values for each maternal tree for $δ^{13}C$. To do this, we will work directly with the mod3 output from before. What we are after is the value of $δ^{13}C$ for each tree from which we measured $δ^{13}C$ from five of her offspring in the common garden. This is the genetic value and represents the value of $δ^{13}C$ that would result if you knew all the genes and effect sizes of variation within those genes determining variation for this trait (see genetics without molecular markers!).

To get the effects due to family and population, we can use the ranef() function. This function produces estimates for each family and population in a list with named elements ('family' and 'population').

First, let’s get the list we need: 

```{r}
mod3_eff <- ranef(mod3)
head(mod3_eff$family)
```

The values look strange relative to the original values in the phen object. It turns out that values in each element are relative to the global intercept listed in the 'mod3' output. So, for example, family 59 has a value of $δ^{13}C$ that is 0.269382818 greater than the mean, whereas family 65 has a value of $δ^{13}C$ 0.159631179 less than the mean. Look in the 'mod3' output by printing it to screen and finding the global intercept (-30.59964).

Now, we need to add this number to the values in the $family output in mod3_effs: 

```{r}
mod3_fam_only <- mod3_eff$family + -30.59964
head(mod3_fam_only)
```

We still are not done. Remember that families were nested within populations, so the total effect of a maternal tree was partitioned into an effect of population and trees within populations. Therefore, we should add the population effect to the numbers from in 'mod3_fam_only'. 

To get this we need to replicate the values in the $population part of the list for each tree in each population. You can just use the pop_rep function provided in "supplemental_R_functions.R":

```{r}
mod3_all_eff <- mod3_fam_only + pop_rep(pop.eff = mod3_eff$population, 
                                        n.fam = nrow(mod3_eff$family), 
                                        fam.eff = mod3_eff$family)
head(mod3_all_eff)
```

The values held in the object mod3_all_eff are now the genetic effects of each maternal tree. In other words, this is the phenotypic trait value for the maternal tree for $δ^{13}C$. Note that we did not measure the maternal tree, but inferred her phenotype from her offspring in a common environment.

## 3. Estimate trait heritability

**Motivation**: Now that we have learned how to estimate genetic values for $δ^{13}C$, let’s learn how to estimate what fraction of the total variation in trait values is due to genetic effects and how much of this genetic effect is due to families nested within populations and to populations. These analyses provide key information about whether or not local adaptation should even be considered. Remember that local adaptation is about genetically determined phenotypes that vary across environments in responses to differing selective pressures. This step allows us to assess how genetic variation for a phenotypic trait is distributed across the landscape.

**Goals & Background**: The goal for this part of the laboratory is to estimate heritability, trait differentiation, and correlation with environment for trait values determined in Part 1. To do this, we will be using the output from the previous part of the laboratory and the environmental data contained in the file named "WWP_environmental_data.txt". As with the phenotype file this is a tab-delimited text file.

### a) Estimate heritability

Let’s start with estimating the heritability of $δ^{13}C$. If you remember from your undergraduate evolution course, heritability refers generally to the proportion of phenotypic variance due to genetic variance. It comes in at least two different versions. The version we are interested in is narrow-sense heritability ($h^2$), which is defined as the ratio of additive genetic variance to total phenotypic variance:

$$h^{2} = \frac{\sigma^{2}_{additive}}{\sigma^{2}_{total}}$$
We need to extract the variance components from 'mod3' for all model terms. We do this visually by printing mod3 to screen or using a set of functions applied to 'mod3'. For this lab, let’s do it visually.

```{r}
mod3
```

Using the results from above, let’s calculate $h^2$. If we assume that the seedlings from each maternal tree are half-siblings (i.e. same mom, but each with a different father) then $σ^2_A = 4 σ^2_{family}$ (so variance due to family:population). If the seedlings were all full-siblings, then the 4 would be replaced with 2. We also need to realize that we are using a hierarchical model, where some of the genetic effects are due to among populations, where $h^2$ is a measure within populations. That means we have to ignore the variance due to populations. Let’s assume half-siblings. We can then do the following:

```{r}
add_var <- 4*(0.2831^2)
total_wp_var <- (0.2831^2) + (0.8509^2)
h2 <- add_var/total_wp_var
h2
```

Inspect your value of $h^2$. What does it mean? Why did we square the values above?

We have generated a point estimate for $h^2$. It represents the average $h^2$ across populations after removing the genetic effects due to population differences. Would it not be nice to also have a confidence interval? We can do that through an approach known as parametric bootstrapping. This approach simulates data using the fitted model a large number of times. Using the resulting distribution, you can create confidence intervals using the appropriate symmetric quantiles of the distribution. To see this, please
do the following using the mod_boot function in "supplemental_R_functions.R". It will takes a few moments to run the first line.

```{r}
h2_boot_out <- mod_boot(model = mod3, nboot = 1000)
ci_95 <- quantile(h2_boot_out, probs = c(0.025, 0.50, 0.975)) ### this is a 95% ci.
ci_95
boxplot(h2_boot_out, range=5); abline(h = h2, col = "red") ## the red line is our original h2 estimate   for   comparison   to   the   bootstrapdistribution.
```

Interpret the confidence intervals 'ci_95' and boxplot with our original $h^2$ estimate for comparison to the bootstrap distribution. Do you think that $h^2$ is statistically different than zero? Is this consistent with the AIC results from Part 1? Is it meaningful that the red line is very similar to the mean (or median) of the bootstrap distribution? How would you change the code for a 99% confidence interval?

### b) Estimate trait differentiation

Great, we have shown that within population genetic variation is statistically greater than zero. What about among population genetic variation? Let’s get to that right now. To measure among population genetic variation we will use a statistic known as $Q_{ST}$. It is similar in concept to $F_{ST}$ from population genetics. To estimate $Q_{ST}$, we will use our LMM output again. If we assume that all seedlings are again half-siblings, then:

$$Q_{ST} = \frac{\sigma^{2}_{population}}
{\sigma^{2}_{population}+8\sigma^{2}_{family}}$$

```{r}
num_qst <- 0.3088^2
dem_qst <- (0.3088^2) + (8*(0.2831^2))
qst <- num_qst/dem_qst
```

Inspect your value in qst object. What does it mean? Look at the quantities
in the equation above, what is the denominator equal to? Is it the total
phenotypic variance or the total genetic variance?

Now, we can again look at a confidence interval using parametric bootstrapping. Again, please use the function 'mod_boot_qst' that is also located in "supplemental_R_functions.R". As before, it will take a few moments for the first line to finish.

```{r}
qst_boot_out <- mod_boot_qst(model = mod3, nboot = 1000)
ci_95_qst <- quantile(qst_boot_out, probs = c(0.025, 0.50, 0.975)) ### this is a 95% ci.
ci_95_qst
boxplot(qst_boot_out); abline(h = qst, col = "red")
```

Interpret the results. Do you think that $Q_{ST}$ is statistically different than zero? Is this consistent with the AIC results from Part 1? Is it meaningful that the red line is less similar to the mean (or median) of the bootstrap distribution as compared to $h^2$?

### c) Estimate trait correlation with environment

The last thing we want to do in this part of the lab is to test for correlations
between genetic values of $δ^{13}C$ and environmental data.

First,we need to load the environmental and geographical data.

```{r}
env <- read.delim(paste0(here(),"/data/WWP_environmental_data.txt"), sep = "\t", header = T)
```

First,let’s standardize all the data. This means let’s subtract the mean and divide by the standard deviation for each geographical and environmental variable. Luckily, R has a function called scale() that will do this for us.

```{r}
env2 <- data.frame(matrix(nrow=nrow(env), ncol=ncol(env)))
colnames(env2) <- colnames(env)
env2[,c(1:2)] <- env[,c(1:2)]
for(i in 3:ncol(env2)) {env2[,i] <- scale(env[,i], center = T, scale = T)}
```

Second, let’s use multiple regression to test the effect of these variables on $δ^{13}C$. Luckily, our genetic values in mod3_all_eff are in the same order as the environmental data.

First, join the data: 

```{r}
phen_env <- cbind(mod3_all_eff[,1], env2[,c(3:11)])
colnames(phen_env) <- c("d13c", colnames(env2)[3:11])
mod1_env <- lm(d13c ~ longitude + latitude + elev + max_rad + tmax_july + tmin_jan + ann_ppt + gdd_aug + AWS050, data = phen_env)
```

This model tells us the effect of all variables on $δ^{13}C$. Use 'summary' to get relevant statistics.

```{r}
summary(mod1_env)
```

Now, let’s get the effect of climate conditioned on longitude and latitude.

```{r}
res_geog <- residuals(lm(d13c ~ longitude + latitude, data = phen_env))
phen_env_mod2 <- cbind(res_geog, env2[,5:11])
mod2_env <- lm(d13c ~ elev + max_rad + tmax_july + tmin_jan + ann_ppt + gdd_aug + AWS050, data = phen_env)
summary(mod2_env)
```

This model gives the effect of climate independent of geography. Now, let’s get the effect of geography conditioned on climate.

```{r}
res_clim <- residuals(lm(d13c ~ elev + max_rad + tmax_july + tmin_jan + ann_ppt + gdd_aug + AWS050, data = phen_env))
phen_env_mod3 <- cbind(res_clim, env2[,c(3:4)]); colnames(phen_env_mod3) <- c("d13c", "longitude", "latitude")
mod3_env <- lm(d13c ~ longitude + latitude, data = phen_env_mod3)
summary(mod3_env)
```

This model gives the effect of geography independent of climate.

We can now assess the impact of climate on the genetic values of $δ^{13}C$. Let’s start with model 1.

```{r}
summary(mod1_env)
```

Is this multiple regression model statistically significant? If so, why? Which variables provide the largest effects (use the column labeled 'Estimate', which is the partial regression coefficient)? Do the same sort of inspection for 'mod2_env' and 'mod3_env'. What can you conclude?

```{r}
summary(mod2_env)
summary(mod3_env)
```
